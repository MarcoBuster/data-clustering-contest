<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://thenextweb.com/podium/2019/11/01/your-customers-dont-want-absolute-privacy-just-fair-compensation-for-their-data/"/>
    <meta property="og:site_name" content="Podium | The Next Web"/>
    <meta property="article:published_time" content="2019-11-01T12:00:56+00:00"/>
    <meta property="og:title" content="Your customers don’t want absolute privacy — just fair compensation for their data"/>
    <meta property="og:description" content="People have the power in the new data landscape, so it’s time to protect privacy and boost transparency across the board."/>
  </head>
  <body>
    <article>
      <h1>Your customers don’t want absolute privacy — just fair compensation for their data</h1>
      <h2>Uncovering what we want (what we really, really want) from our own data</h2>
      <address><time datetime="2019-11-01T12:00:56+00:00">01 Nov 2019, 12:00</time> by <a rel="author">Paul Neto</a></address>
      <p>Has your data ever been mishandled? Chances are, you’ve been one of the millions affected by one of the <a href="https://www.privacyrights.org/data-breaches">9,044 public breaches since 2005</a>, the most recent being the largest bank data theft in history at <a href="https://www.cnn.com/2019/07/29/business/capital-one-data-breach/index.html">Capital One</a>. These are stark reminders of just how vulnerable our personal data can be, and the lack of transparency surrounding how it’s being used. While many of us understand that our data is being used in some way, there is still some mystery surrounding exactly <i>how </i>it is being used and to what extent. </p>
      <p>As such, privacy, data ownership, and corporate responsibility is top of mind – or should be. Corporations like Apple are making public commitments to privacy and stewardship of user data, both from a messaging and product design standpoint. Others (left unnamed) are dealing with data breach fines as legislation is evolving across the globe to punish those who are not part of this new order.</p>
      <p>In the face of all this, I was curious about a different perspective: what do individuals <i>really </i>care about? Corporations are making assumptions, but where is the data to back these up? My team set out to uncover what people really think about privacy, transparency and accountability when it comes to their own data. What we discovered can help all of us navigate this tricky pathway.</p>
      <h3>Getting to the bottom of data privacy</h3>
      <p>If someone asks you “are you concerned about your privacy” it is highly likely that you – and anyone else who is posed the question – will always give you a “yes” response. This presents a challenge with gaining perspective on things like privacy and data ownership, as there is no context.</p>
      <p>If we look at people’s behavior instead of their actual responses to a survey question, we may see something slightly different, but I’d argue it’s only marginally different. We need to step back and start looking at data, privacy, sharing and value differently.</p>
      <p>To explore these important topics, my team tapped into the network of users on our MSR app, where consumers can build their profile and earn rewards for participating in research, sharing data and other data jobs. (It’s important to note here that we make a point of paying our users for their insights as best as we can. After all, we believe opinions, general feedback and ideas are valuable).</p>
      <p>Through our outreach to these users over the past year, we’ve uncovered some directionally interesting data which, although it may not be strictly representative, is worth examining more closely. </p>
      <h3>What really makes people want to share their data? </h3>
      <p>First, through our MSR app, my team asked a group of individuals how concerned they are about the general protection of their privacy. Seventy-four percent said they were either somewhat or extremely concerned. No big surprises here. We went a step further by asking them how likely they’d be to share more data if they felt their privacy was protected, 61 percent indicated that they probably or definitely would. </p>
      <p>Based on these two simple numbers, I believe there is a missed opportunity for empowering decisions with data. If we can all agree that data helps us make better decisions, isn’t it safe to say our data supported decisions are being compromised due to issues around privacy? We see a similar trend when it comes to transparency.</p>
      <p>When we asked our users if they would be willing to share more data if they felt corporations were being more transparent in how they were using the data, we found 77 percent indicating that they probably or definitely would share more. </p>
      <p>Here is where things get interesting. Our team also asked how likely they would be to share more data if they were paid fairly for it. Wait for it . . . 73 percent said they probably or definitely would, with only 7 percent saying they would not (the rest being neutral). So the question becomes, do people care about privacy, do they care about being paid, do they care about transparency or something else entirely?</p>
      <p>My hypothesis is that none of these issues are independent of one another and to optimize for the best results, you need to address each one reasonably well. Just think of the iPhone when it was first released. It didn’t really have any particular functions that were better than any other device, other than the cool-factor. It was just good enough across more factors that consumers actually cared about, and Apple communicated these strengths. </p>
      <h3>Diving in deeper to what makes people tick</h3>
      <p>We were very intrigued with this, so as part of another study, we asked a group of users to rank, in order of importance, things like protecting privacy, getting paid fairly, data control, transparency, and others. When rank ordering the list, this forces the respondent to define one priority over others. To our surprise, ‘protecting privacy’ was just ahead of ‘getting paid fairly.’ My interpretation is that again, these factors are not independent of one another and there may be a steep trade-off curve. </p>
      <p>Despite all this data, there is a reality that most of us are faced with — we simply don’t feel we have a choice in most cases. We asked a group of our users how they feel about their level of control over their personal data used by smartphone apps and devices. We found 44 percent responding with “I know they use my data when I agree to their terms and conditions but I don’t feel I have a choice.” For this reason, our team feels that users should have a choice and a say. </p>
      <p>As such, for every data job (e.g. survey) we ask them to rate the engagement in an uber-style five-star rating <i>and</i> provide some context to why. What we found is that the top reasons for a 1-3 star rating was “payment was too small” (41 percent) and the survey was “too long” (18 percent), and the top reasons for a 4-5 star rating included “easy to understand” (24 percent) and simple (20 percent). It is upon us to empower users with data and to use this type of feedback to ensure we are engaging in a meaningful way. (Hint-hint, this also lends to some interesting game theory research — more to come on that.)</p>
      <p>There has been a fundamental shift if the digital ecosystem where we as individuals are taking the stage as the primary stakeholders. While companies and brands exist to make money, there is a realization that if you take care of people, and empower them, everything downstream becomes mutually beneficial, you just need to figure out what consumers really want, and if you get it wrong, be relentless trying to figure it out.</p>
    </article>
  </body>
</html>