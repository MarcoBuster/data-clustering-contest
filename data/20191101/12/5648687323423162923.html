<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://www.fr.de/kultur/filter-fakten-13183517.html"/>
    <meta property="og:site_name" content="Frankfurter Rundschau"/>
    <meta property="article:published_time" content="2019-11-01T12:33:00+00:00"/>
    <meta property="og:title" content="Filter und Fakten"/>
    <meta property="og:description" content="Soziale Netzwerke sollen Radikalisierung fördern und zu Parallelwelten führen. Gibt es dafür wissenschaftliche Belege?"/>
  </head>
  <body>
    <article>
      <h6 class="kicker">Update</h6>
      <h1>Filter und Fakten</h1>
      <address><time datetime="2019-11-01T12:33:00+00:00">01 Nov 2019, 12:33</time> by <a rel="author">Kathrin Passig</a></address>
      <p>
        <b>Soziale Netzwerke sollen Radikalisierung fördern und zu Parallelwelten führen. Gibt es dafür wissenschaftliche Belege?</b>
      </p>
      <p>Vor acht Jahren ist der Begriff der „Filterblase“ in den Diskussionen um Internetangelegenheiten aufgetaucht und seitdem nicht mehr verschwunden. Es ging damals vor allem personalisierte Suchergebnisse zum Beispiel bei Google, die die Vorlieben einer Person aus deren bisherigem Nutzungsverhalten abzuleiten versuchen. Dadurch bekomme man, so lautete der Vorwurf, nur noch Informationen vorgesetzt, die eine schon vorhandene Meinung weiter verstärken. Das deutsche Wort „Blase“ klingt fragil, nach etwas, das schnell wieder platzt. Gemeint ist aber ein robuster Raum, der von den Ansichten anderer Menschen abschottet.</p>
      <p>Seit den US-Wahlen von 2016 geht es, wenn das Wort Filterblase fällt, kaum noch um personalisierte Google-Ergebnisse. Die Diskussion hat sich auf die Vorgänge in sozialen Netzwerken verlagert. Gleichgesinnte, so heißt es, bestärken einander in ihren Meinungen, fallen auf falsche Nachrichten herein, bekommen von anderen Lebensweisen nichts mehr mit und entfernen sich so immer weiter von anderen Gruppen. Sortier- und Empfehlungssysteme, die bei Facebook bestimmte Beiträge in der Timeline sichtbarer machen und bei Youtube zu ähnlichen Videos führen, unterstützen diese Aufspaltung in Parallelwelten.</p>
      <p>So lautet jedenfalls die Theorie.</p>
      <p>Eine Studie aus dem Jahr 2018 (Shore, Baek und Dellarocas) ergab jedoch, dass die überwiegende Mehrheit der aktiven Twitter-Nutzerinnen und -Nutzer dort im Widerspruch zur Filterblasentheorie Nachrichten schreibt, die politisch nicht extremer sind als diejenigen Nachrichten, die sie zur Kenntnis nimmt, sondern moderater. Die typische Twitter-Timeline enthält Links zu Nachrichtenartikeln aus dem gesamten politischen Spektrum. Die Intensiv-Twitterer folgen politisch noch diverseren Accounts als die Normalnutzer. An Kontakt zu anderen Sichtweisen mangelte es keiner der beiden Gruppen.</p>
      <figure>
        <img src="https://www.fr.de/bilder/2019/10/31/13183517/2112469791-vp_0fr710frd-b_123051_1_1_1_17-JMG.jpg"/>
        <figcaption>Hier schreibt Kathrin Passig jede Woche über Themen des digitalen Zeitalters. Sie ist Mitbegründerin des Blogs „Techniktagebuch“. www.kathrin.passig.de<cite>© Norman Posselt</cite></figcaption>
      </figure>
      <p>Eine weitere 2019 erschienene Studie (Becker, Porter und Centola) widmet sich der Frage, wie die Beobachtung der „Wisdom of Crowds“ zur Filterblasentheorie passt. Die Idee von der „Wisdom of Crowds“ ist älter als das Netz und beschreibt, dass Menschen in der Summe ihrer Meinungen zu besseren Zukunftsvorhersagen oder Schätzwerten gelangen als Einzelne, selbst wenn diese Einzelnen Fachleute sind, weil sich die individuellen Irrtümer gleichmäßig verteilen.</p>
      <p>Nach der Filterblasentheorie müsste die Situation in sozialen Netzwerken diesen Effekt verhindern, und die Irrtümer müssten in eine bestimmte Richtung ausschlagen. Die Studie – die allerdings in einer experimentellen Umgebung und nicht in einem realen sozialen Netzwerk durchgeführt wurde – kommt zum entgegengesetzten Schluss: Selbst wenn zwei politisch polarisierte Gruppen gar nicht direkt miteinander kommunizieren, führt schon der Austausch innerhalb der jeweiligen Gruppen zu korrekteren Ergebnissen bei Faktenfragen und reduziert die Radikalisierung.</p>
      <p>Eine dritte Studie aus dem Jahr 2019 (Nguyen und Vu) untersuchte die Frage, ob Menschen, die ihre Politiknachrichten vorwiegend aus sozialen Netzwerken beziehen, dadurch stärker radikalisiert werden als solche, die sich auf Radio, Fernsehen, Zeitungen oder das Netz außerhalb sozialer Netzwerke verlassen. Zu diesem Zweck analysierten die Autoren die in der „Eurobarometer“-Umfrage von 2016 abgefragten Ansichten über die EU. Wie sich herausstellte, hat die Wahl der Nachrichtenquelle keinen signifikanten Einfluss.</p>
      <p>Die Vorstellung, dass die Meinungen anderer Leute irgendwie durch eine technische Neuerung verursacht werden, ist attraktiv, aber nicht so leicht zu belegen. Dass die falschen und empörenden Meinungen anderer Leute in den vergangenen Jahren überhaupt zum Debattenthema geworden sind, hat mit ihrer gestiegenen Sichtbarkeit zu tun. Man kann den sozialen Netzwerken aber nicht vorwerfen, dass sie hermetisch abgeschottete Räume erzeugen und dass sie uns gleichzeitig mit der Existenz der darin vertretenen Ansichten konfrontieren. Zuverlässig funktionierende Filterblasen würden die Welt friedlicher und einmütiger wirken lassen, nicht umgekehrt.</p>
      <p>Selbst wenn ich mich im Netz einer Gruppe aus hundertprozentig konformen Befürwortern des großen ß in der Typographie oder Gegnern einer Fahrradhelmpflicht anschließe, wird es darin auch um Fragen des Sprachgebrauchs, der Politik und der Haustierhaltung gehen. In diesen Fragen wird nicht nur keine Einigkeit herrschen, ich werde dadurch auch von Lebensweisen und Ansichten erfahren, die mir bis dahin ganz unbekannt waren. Das ist lästig, aber leider unvermeidlich. Man hört, es sei sogar schon vor der Erfindung des Internets so ähnlich gewesen.</p>
    </article>
  </body>
</html>