<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <meta property="og:url" content="https://meduza.io/feature/2019/11/01/vlasti-kitaya-nachali-primenyat-dlya-slezhki-za-uygurami-tehnologiyu-raspoznavaniya-emotsiy-uchenye-uvereny-chto-ey-nelzya-doveryat"/>
    <meta property="og:site_name" content="Meduza"/>
    <meta property="article:published_time" content="2019-11-01T12:07:00+00:00"/>
    <meta property="og:title" content="Власти Китая начали применять для слежки за уйгурами технологию распознавания эмоций. Ученые уверены, что ей нельзя доверять"/>
    <meta property="og:description" content="В Китае начали внедрять технологию распознавания эмоций. Ее применяют, в частности, в Синьцзян-Уйгурском автономном районе — регионе на северо-западе страны, где живут преимущественно уйгуры, исповедующие ислам. Китайские власти подозревают жителей Синьцзяна в сепаратистских настроениях, много лет ведут за ним постоянную слежку и отправляют в «воспитательные» лагеря."/>
  </head>
  <body>
    <article>
      <h6 class="kicker">Требует подтверждения</h6>
      <h1>Власти Китая начали применять для слежки за уйгурами технологию распознавания эмоций. Ученые уверены, что ей нельзя доверять</h1>
      <address><time datetime="2019-11-01T12:07:00+00:00">01 Nov 2019, 12:07</time> by <a rel="author" href="https://www.ft.com/content/68155560-fbd1-11e9-a354-36acbbb0d9b6" target="_blank">The Financial Times</a></address>
      <p>В Китае начали внедрять технологию распознавания эмоций. Ее применяют, в частности, в Синьцзян-Уйгурском автономном районе — регионе на северо-западе страны, где живут преимущественно уйгуры, исповедующие ислам. Китайские власти подозревают жителей Синьцзяна в сепаратистских настроениях, много лет ведут за ним постоянную слежку и отправляют в <a href="https://meduza.io/video/2018/11/30/ya-dumala-chto-luchshe-umeret-chem-prohodit-cherez-eti-pytki-uygurka-rasskazala-komissii-kongressa-ssha-o-prebyvanii-v-lagere-v-kitae">«воспитательные» лагеря</a>.</p>
      <p>Как <a href="https://www.ft.com/content/68155560-fbd1-11e9-a354-36acbbb0d9b6">пишет</a> Financial Times, методика распознавания эмоций стала одной из главных тем для обсуждения на крупнейшей в Китае выставке технологий видеонаблюдения, которая <a href="https://www.chinaexhibition.com/trade_events/9828-CPSE_2019_-_The_17th_China_Public_Security_Expo.html">проходила</a> с 21 по 31 октября в городе Шэньчжэнь. Китайские власти говорят, что новая технология, как и внедренные ранее методы распознавания людей по лицу или походке, поможет бороться с преступностью.</p>
      <p>«Алгоритм распознавания эмоций может по видеозаписям быстро вычислить подозреваемых, анализируя их психическое состояние, и предотвратить незаконные действия, включая терроризм и контрабанду. Мы уже начали его использовать», — заявил Financial Times Ли Сяою, эксперт по охране общественного порядка из бюро общественной безопасности в городе Алтай в Синьцзяне.</p>
      <p>Алгоритм выявляет признаки агрессивности и нервозности в облике человека, а также определяет его уровень стресса. «Мы сотрудничаем с разными [производителями оборудования и технологий видеонаблюдения] в Синьцзяне, включая Hikvision, Uniview, Dahua и Tiandy. Только компании, которые всерьез занимаются искусственным интеллектом, могут работать в этой сфере. Лидеры рынка — это, конечно, Alibaba и Tencent», — сказал Ли Сяою.</p>
      <p>По его словам, в Синьцзяне технология используется в первую очередь при прохождении таможенного досмотра. Но, как пишет Financial Times, программы по распознаванию стали подключать к камерам и в метро, в департаментах полиции и в некоторых школах. Неназванный представитель компании Megvii, разрабатывающей программы анализа изображений, рассказал, что китайские власти уже широко используют технологию распознавания эмоций.</p>
      <p>Научить искусственный интеллект понимать чувства человека пытаются не только китайские компании, но и такие международные технологические гиганты как Amazon, Microsoft и Google. Однако ученые считают, что новой технологии пока нельзя доверять. Не потому что она еще не получила достаточного развития, а потому что эмоции человека нельзя надежно распознать по выражению его лица.</p>
      <p>В июле 2019 года в рецензируемом научном журнале «Psychological Science in the Public Interest» <a href="https://journals.sagepub.com/eprint/SAUES8UM69EN8TSMUGF9/full">вышел</a> <u><a href="https://meduza.io/feature/2019/11/01/vlasti-kitaya-nachali-primenyat-dlya-slezhki-za-uygurami-tehnologiyu-raspoznavaniya-emotsiy-uchenye-uvereny-chto-ey-nelzya-doveryat#footnote_752746">систематический обзор</a></u> исследований о мимике и ее связи с эмоциями. Авторы обзора потратили на работу два года и пришли к выводу, что люди выражают свои чувства самыми разными способами. Это означает, что компании, которые расхваливают свои алгоритмы для определения эмоций, скорее всего, преувеличивают их эффективность.</p>
      <p>«Данные показывают, что в среднем люди хмурятся менее чем в 30% ситуаций, когда они испытывают злость», — <a href="https://www.theverge.com/2019/7/25/8929793/emotion-recognition-analysis-ai-machine-learning-facial-expression-review">рассказала</a> The Verge одна из авторов исследования, профессор психологии Северо-Восточного университета в Бостоне Лиза Барретт. «Вы действительно хотели бы, чтобы [выводы о вашем психологическом состоянии] делались на этой основе? В суде, при найме на работу, при постановке диагноза, в аэропорту… если алгоритм точен только в 30% случаев?» — сказала она.</p>
      <details>
        <summary>Примечания</summary>
        <ul>
          <li>
            <anchor name="footnote_752746"><b>Систематический обзор</b><br/>Метод научного исследования, при котором проводится подбор и анализ всех доступных научных статей на определенную тему.</anchor>
          </li>
        </ul>
      </details>
      <related>
        <h4>Как власти Китая следят за уйгурами…</h4>
        <a href="https://meduza.io/feature/2018/09/18/kontslager-na-10-millionov-chelovek"/>
        <a href="https://meduza.io/feature/2019/02/17/v-internete-nashli-bazu-dannyh-podryadchika-kitayskoy-politsii-v-ney-byla-informatsiya-o-slezhke-za-millionami-uygurov"/>
        <a href="https://meduza.io/feature/2019/09/02/kitay-zakazal-krupneyshiy-vzlom-ios-dlya-slezhki-za-uygurami-no-pod-ugrozoy-okazalis-ayfony-vo-vsem-mire-vozmozhno-telefony-na-android-tozhe"/>
      </related>
      <related>
        <h4>… и за всеми остальными</h4>
        <a href="https://meduza.io/feature/2018/04/15/ostryy-glaz-vmesto-bolshogo-brata-kak-kitayskie-vlasti-massovo-sledyat-za-zhitelyami-strany"/>
        <a href="https://meduza.io/feature/2019/04/08/uborschikov-ulits-v-kitae-zastavili-nosit-umnye-braslety-oni-trebuyut-vernutsya-k-rabote-esli-dvornik-ne-dvigaetsya-20-minut"/>
        <a href="https://meduza.io/feature/2019/07/03/na-v-ezde-v-musulmanskiy-rayon-kitaya-u-turistov-skaniruyut-telefony-s-pomoschyu-shpionskogo-prilozheniya-ono-skachivaet-vse-dannye-i-ischet-snimki-dalay-lamy"/>
      </related>
      <footer>Пересказала <b>Ольга Корелина</b></footer>
    </article>
  </body>
</html>